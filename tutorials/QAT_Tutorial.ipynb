{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "T36BGn9jqXLb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonu/code/model_quantization/.venv/lib/python3.11/site-packages/fastprogress/fastprogress.py:107: UserWarning: Couldn't import ipywidgets properly, progress bar will use console behavior\n",
      "  warn(\"Couldn't import ipywidgets properly, progress bar will use console behavior\")\n"
     ]
    }
   ],
   "source": [
    "# importing the necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "\n",
    "_ = torch.manual_seed(0)\n",
    "\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    size = os.path.getsize(\"temp_delme.p\")/1e3\n",
    "    print('Size (KB):', size)\n",
    "    os.remove('temp_delme.p')\n",
    "    return size\n",
    "\n",
    "\n",
    "# Define the network:\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub() # quantization layer\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.reshape(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(model, train_dl, valid_dl, criterion, optimizer):\n",
    "    mb = master_bar(range(5))\n",
    "    for epoch in mb:\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        # Progress bar for training batches\n",
    "        pb = progress_bar(train_dl, parent=mb)\n",
    "\n",
    "        for inputs, labels in pb:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Compute training accuracy\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "            mb.child.comment = f\"Train Loss: {loss.item():.4f}\"\n",
    "\n",
    "        # Compute average train loss & accuracy\n",
    "        avg_train_loss = running_loss / len(train_dl)\n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "\n",
    "        # Validation Phase (No Gradients)\n",
    "        val_loss = 0.0\n",
    "        correct_val, total_val = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Progress bar for validation\n",
    "            pb = progress_bar(valid_dl, parent=mb)\n",
    "\n",
    "            for inputs, labels in pb:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Compute validation accuracy\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                correct_val += (preds == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "                mb.child.comment = f\"Valid Loss: {loss.item():.4f}\"\n",
    "\n",
    "        # Compute average validation loss & accuracy\n",
    "        avg_val_loss = val_loss / len(valid_dl)\n",
    "        val_accuracy = correct_val / total_val * 100\n",
    "\n",
    "        # Write epoch summary\n",
    "        mb.write(f\"Epoch {epoch+1}: \"\n",
    "                 f\"Train Loss={avg_train_loss:.4f}, Train Acc={train_accuracy:.2f}% | \"\n",
    "                 f\"Val Loss={avg_val_loss: .4f}, Val Acc={val_accuracy: .2f}\")\n",
    "\n",
    "\n",
    "# evaluate\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"test acc\", correct / total)\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "def calibrate(model, dl):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, _) in enumerate(tqdm(dl)):\n",
    "            model(images)\n",
    "            if idx == 4:\n",
    "                break\n",
    "    return model\n",
    "\n",
    "\n",
    "def quantize_model(model, train_loader):\n",
    "    # Create quantization-ready model\n",
    "    qmodel = Net().to('cpu')  # quantization needs to happen on CPU\n",
    "    qmodel.load_state_dict(model.state_dict())\n",
    "    qmodel.eval()\n",
    "\n",
    "    # Set qconfig for static quantization\n",
    "    qmodel.qconfig = torch.ao.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "    # Prepare model for quantization (adds observers)\n",
    "    qmodel = torch.ao.quantization.prepare(qmodel)\n",
    "\n",
    "    # Calibrate the model\n",
    "    calibrate(qmodel, train_loader)\n",
    "\n",
    "    # Convert to quantized model\n",
    "    qmodel = torch.ao.quantization.convert(qmodel)\n",
    "\n",
    "    return qmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OaCyTpCM5wJ2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ds length 40000\n",
      "test ds length 10000\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "tfms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# dataset and dataloader\n",
    "train_ds = torchvision.datasets.CIFAR10(\n",
    "    root='./data/cifar', train=True, transform=tfms, download=True)\n",
    "test_ds = torchvision.datasets.CIFAR10(\n",
    "    root='./data/cifar', train=False, transform=tfms, download=True)\n",
    "\n",
    "train_ds, valid_ds = random_split(train_ds, [40000, 10000])\n",
    "print(f\"train ds length {len(train_ds)}\")\n",
    "print(f\"test ds length {len(test_ds)}\")\n",
    "# train_ds = Subset(train_ds, range(100))\n",
    "# valid_ds = Subset(train_ds, range(100))\n",
    "# test_ds = Subset(train_ds, range(100))\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = torch.utils.data.DataLoader(\n",
    "    valid_ds, batch_size=batch_size, shuffle=False)\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_gmqtQpk508e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model before training\n",
      "Net(\n",
      "  (quant): QuantStub(\n",
      "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (conv1): Conv2d(\n",
      "    3, 6, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(\n",
      "    6, 16, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (fc1): Linear(\n",
      "    in_features=400, out_features=120, bias=True\n",
      "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (fc2): Linear(\n",
      "    in_features=120, out_features=84, bias=True\n",
      "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (fc3): Linear(\n",
      "    in_features=84, out_features=10, bias=True\n",
      "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "  )\n",
      "  (dequant): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# insert min-max observers in the model\n",
    "model = Net().to(device)\n",
    "model.train()\n",
    "model.qconfig = torch.ao.quantization.default_qconfig\n",
    "model = torch.ao.quantization.prepare_qat(model)\n",
    "print(\"Model before training\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "s5M1cEHB53KK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.2679, Train Acc=14.82% | Val Loss= 2.1236, Val Acc= 25.06                     \n",
      "Epoch 2: Train Loss=1.9576, Train Acc=29.41% | Val Loss= 1.7920, Val Acc= 35.13                     \n",
      "Epoch 3: Train Loss=1.6837, Train Acc=38.14% | Val Loss= 1.5950, Val Acc= 42.33                     \n",
      "Epoch 4: Train Loss=1.5304, Train Acc=44.22% | Val Loss= 1.5104, Val Acc= 44.51                     \n",
      "Epoch 5: Train Loss=1.4410, Train Acc=48.04% | Val Loss= 1.4249, Val Acc= 48.83                     \n"
     ]
    }
   ],
   "source": [
    "# defining loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# saving the model\n",
    "model_path = \"model_qat.pkl\"\n",
    "if Path(model_path).exists():\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print('model loaded successfully')\n",
    "else:\n",
    "    train_model(model, train_dl, valid_dl, criterion, optimizer)\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9tRSDZHr56F-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model after training\n",
      "Net(\n",
      "  (quant): QuantStub(\n",
      "    (activation_post_process): MinMaxObserver(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (conv1): Conv2d(\n",
      "    3, 6, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (weight_fake_quant): MinMaxObserver(min_val=-0.29749810695648193, max_val=0.3572477102279663)\n",
      "    (activation_post_process): MinMaxObserver(min_val=-5.882468223571777, max_val=5.583756446838379)\n",
      "  )\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(\n",
      "    6, 16, kernel_size=(5, 5), stride=(1, 1)\n",
      "    (weight_fake_quant): MinMaxObserver(min_val=-0.21562230587005615, max_val=0.22265036404132843)\n",
      "    (activation_post_process): MinMaxObserver(min_val=-9.163378715515137, max_val=11.960596084594727)\n",
      "  )\n",
      "  (fc1): Linear(\n",
      "    in_features=400, out_features=120, bias=True\n",
      "    (weight_fake_quant): MinMaxObserver(min_val=-0.11489372700452805, max_val=0.10775470733642578)\n",
      "    (activation_post_process): MinMaxObserver(min_val=-8.196516036987305, max_val=10.785405158996582)\n",
      "  )\n",
      "  (fc2): Linear(\n",
      "    in_features=120, out_features=84, bias=True\n",
      "    (weight_fake_quant): MinMaxObserver(min_val=-0.16707557439804077, max_val=0.161978617310524)\n",
      "    (activation_post_process): MinMaxObserver(min_val=-5.280505657196045, max_val=10.2288818359375)\n",
      "  )\n",
      "  (fc3): Linear(\n",
      "    in_features=84, out_features=10, bias=True\n",
      "    (weight_fake_quant): MinMaxObserver(min_val=-0.32933515310287476, max_val=0.34288862347602844)\n",
      "    (activation_post_process): MinMaxObserver(min_val=-8.456645011901855, max_val=10.848601341247559)\n",
      "  )\n",
      "  (dequant): DeQuantStub()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Model after training\")\n",
    "print(model)\n",
    "# quantization of model\n",
    "model.eval()\n",
    "model = torch.ao.quantization.convert(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vppf7XSO5tKP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after quantization\n",
      "tensor([[ -4, -21,  57,  ...,  37,  39, -76],\n",
      "        [-11,   7,  12,  ...,  10,  17,  78],\n",
      "        [ -5, -13,  70,  ...,  12, -45,  20],\n",
      "        ...,\n",
      "        [ 13,  -6, -11,  ..., -33, -37,   6],\n",
      "        [ 29,  -4,  19,  ..., -63, -46,  30],\n",
      "        [ 23,   9, -25,  ...,   0,   7,  52]], dtype=torch.int8)\n",
      "Size of the model after quantization\n",
      "Size (KB): 69.922\n",
      "Accuracy of the model after quantization: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:02<00:00, 106.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc 0.486\n",
      "Prec   | Accuracy | Model Size | Time Taken\n",
      "INT8   | 0.4860   | 69.922     | 2.949037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Weights after quantization')\n",
    "print(torch.int_repr(model.fc1.weight()))\n",
    "print('Size of the model after quantization')\n",
    "q_size = print_size_of_model(model)\n",
    "print('Accuracy of the model after quantization: ')\n",
    "start = time.time()\n",
    "q_acc = evaluate(model, test_dl)\n",
    "end = time.time()\n",
    "q_time = end-start\n",
    "\n",
    "print(f\"{'Prec':<6} | {'Accuracy':<8} | {'Model Size':<10} | {'Time Taken'}\")\n",
    "print(f\"{'INT8':<6} | {q_acc:<8.4f} | {q_size:<10.3f} | {q_time:<.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPKjKBir8iARGcvBCknVmww",
   "provenance": [
    {
     "file_id": "1As963hzJYDvgmEzNxsNHxtNojgN7qsGt",
     "timestamp": 1740030612954
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
