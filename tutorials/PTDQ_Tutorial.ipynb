{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2AJKAEwr6zL"
   },
   "source": [
    "# Post Training Dynamic Quantization\n",
    "\n",
    "In Dynamic quantization we calculate the scale factor for the activations dynamically based on the data observed at runtime.\n",
    "\n",
    "The model parameter are already known during conversion and so they are convered and stored in INT8 before inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wr-Ztv5rr2gA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonu/code/model_quantization/.venv/lib/python3.11/site-packages/fastprogress/fastprogress.py:107: UserWarning: Couldn't import ipywidgets properly, progress bar will use console behavior\n",
      "  warn(\"Couldn't import ipywidgets properly, progress bar will use console behavior\")\n"
     ]
    }
   ],
   "source": [
    "# importing the necessary libraries\n",
    "import torch\n",
    "from torch.quantization import quantize\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    size = os.path.getsize(\"temp_delme.p\")/1e3\n",
    "    print('Size (KB):', size)\n",
    "    os.remove('temp_delme.p')\n",
    "    return size\n",
    "\n",
    "\n",
    "# Define the network:\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(model, train_dl, valid_dl, criterion, optimizer):\n",
    "    mb = master_bar(range(5))\n",
    "    for epoch in mb:\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        # Progress bar for training batches\n",
    "        pb = progress_bar(train_dl, parent=mb)\n",
    "\n",
    "        for inputs, labels in pb:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Compute training accuracy\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "            mb.child.comment = f\"Train Loss: {loss.item():.4f}\"\n",
    "\n",
    "        # Compute average train loss & accuracy\n",
    "        avg_train_loss = running_loss / len(train_dl)\n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "\n",
    "        # Validation Phase (No Gradients)\n",
    "        val_loss = 0.0\n",
    "        correct_val, total_val = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Progress bar for validation\n",
    "            pb = progress_bar(valid_dl, parent=mb)\n",
    "\n",
    "            for inputs, labels in pb:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Compute validation accuracy\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                correct_val += (preds == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "                mb.child.comment = f\"Valid Loss: {loss.item():.4f}\"\n",
    "\n",
    "        # Compute average validation loss & accuracy\n",
    "        avg_val_loss = val_loss / len(valid_dl)\n",
    "        val_accuracy = correct_val / total_val * 100\n",
    "\n",
    "        # Write epoch summary\n",
    "        mb.write(f\"Epoch {epoch+1}: \"\n",
    "                 f\"Train Loss={avg_train_loss:.4f}, Train Acc={train_accuracy:.2f}% | \"\n",
    "                 f\"Val Loss={avg_val_loss: .4f}, Val Acc={val_accuracy: .2f}\")\n",
    "\n",
    "\n",
    "# evaluate\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"test acc\", correct / total)\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aQ1QMKlMuSZP"
   },
   "outputs": [],
   "source": [
    "# config\n",
    "tfms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BtcfCkdUuU7I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ds length 40000\n",
      "test ds length 10000\n"
     ]
    }
   ],
   "source": [
    "# dataset and dataloader\n",
    "train_ds = torchvision.datasets.CIFAR10(\n",
    "    root='./data/cifar', train=True, transform=tfms, download=True)\n",
    "test_ds = torchvision.datasets.CIFAR10(\n",
    "    root='./data/cifar', train=False, transform=tfms, download=True)\n",
    "\n",
    "train_ds, valid_ds = random_split(train_ds, [40000, 10000])\n",
    "print(f\"train ds length {len(train_ds)}\")\n",
    "print(f\"test ds length {len(test_ds)}\")\n",
    "# train_ds = Subset(train_ds, range(100))\n",
    "# valid_ds = Subset(train_ds, range(100))\n",
    "# test_ds = Subset(train_ds, range(100))\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = torch.utils.data.DataLoader(\n",
    "    valid_ds, batch_size=batch_size, shuffle=False)\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8c55aXf5uXnu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.2590, Train Acc=14.86% | Val Loss= 2.0955, Val Acc= 23.00                     \n",
      "Epoch 2: Train Loss=1.9649, Train Acc=28.44% | Val Loss= 1.8663, Val Acc= 31.34                     \n",
      "Epoch 3: Train Loss=1.7319, Train Acc=36.78% | Val Loss= 1.6596, Val Acc= 39.01                     \n",
      "Epoch 4: Train Loss=1.5727, Train Acc=42.14% | Val Loss= 1.5431, Val Acc= 43.80                     \n",
      "Epoch 5: Train Loss=1.4839, Train Acc=46.12% | Val Loss= 1.4437, Val Acc= 47.26                     \n"
     ]
    }
   ],
   "source": [
    "# defining loss function and optimizer\n",
    "model = Net()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# saving the model\n",
    "model_path = \"model.pkl\"\n",
    "if Path(model_path).exists():\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print('model loaded successfully')\n",
    "else:\n",
    "    train_model(model, train_dl, valid_dl, criterion, optimizer)\n",
    "    torch.save(model.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "12bVTrPaubV-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before quantization\n",
      "Parameter containing:\n",
      "tensor([[ 0.0104, -0.0451, -0.0420,  ..., -0.0018, -0.0146,  0.0187],\n",
      "        [-0.0603,  0.0163,  0.0094,  ...,  0.0270, -0.0356,  0.0184],\n",
      "        [-0.0088,  0.0259,  0.0162,  ..., -0.0550,  0.0287,  0.0143],\n",
      "        ...,\n",
      "        [-0.0406, -0.0324,  0.0329,  ...,  0.0080, -0.0130, -0.0109],\n",
      "        [-0.0100, -0.0422,  0.0076,  ..., -0.0117, -0.0102,  0.0500],\n",
      "        [ 0.0027,  0.0210,  0.0457,  ..., -0.0049, -0.0600, -0.0109]],\n",
      "       requires_grad=True)\n",
      "torch.float32\n",
      "Size of the model before quantization\n",
      "Size (KB): 251.618\n",
      "Accuracy of the model before quantization: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 171.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc 0.4745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Weights before quantization')\n",
    "print(model.fc1.weight)\n",
    "print(model.fc1.weight.dtype)\n",
    "print('Size of the model before quantization')\n",
    "o_size = print_size_of_model(model)\n",
    "print('Accuracy of the model before quantization: ')\n",
    "tik = time.time()\n",
    "o_acc = evaluate(model, test_dl)\n",
    "tok = time.time()\n",
    "o_time = tok-tik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GXL3Qd80UqB"
   },
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIUdKz6_26MQ"
   },
   "source": [
    "- We select layers to quantize (like Linear layers)\n",
    "- Not all layers are compatible for dynamic quantization.\n",
    "- The weights of these layers are quantized to int8 ahead of time\n",
    "- The model continues to take float32 inputs\n",
    "\n",
    "1. **Input Handling**:\n",
    "   - When float32 input hits a quantized layer\n",
    "   - The input is temporarily quantized to int8 just for the matrix multiplication\n",
    "   - This is done because int8 × int8 is much faster than float32 × float32 on CPU\n",
    "   - This temporary quantization uses dynamic scaling factors calculated on-the-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hJnNSQaLuf47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying post training dynamic quantization on model\n"
     ]
    }
   ],
   "source": [
    "print(\"applying post training dynamic quantization on model\")\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bK6BLWnIukXW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model summary\n",
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): DynamicQuantizedLinear(in_features=400, out_features=120, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (fc2): DynamicQuantizedLinear(in_features=120, out_features=84, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (fc3): DynamicQuantizedLinear(in_features=84, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      ")\n",
      "Weights after quantization\n",
      "tensor([[ 10, -42, -39,  ...,  -2, -14,  17],\n",
      "        [-56,  15,   9,  ...,  25, -33,  17],\n",
      "        [ -8,  24,  15,  ..., -51,  27,  13],\n",
      "        ...,\n",
      "        [-38, -30,  31,  ...,   7, -12, -10],\n",
      "        [ -9, -39,   7,  ..., -11, -10,  47],\n",
      "        [  3,  20,  43,  ...,  -5, -56, -10]], dtype=torch.int8)\n",
      "Size of the model after quantization\n",
      "Size (KB): 76.834\n",
      "Accuracy of the model after quantization: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:02<00:00, 117.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc 0.4753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"model summary\")\n",
    "print(quantized_model)\n",
    "print('Weights after quantization')\n",
    "print(torch.int_repr(quantized_model.fc1.weight()))\n",
    "print('Size of the model after quantization')\n",
    "q_size = print_size_of_model(quantized_model)\n",
    "print('Accuracy of the model after quantization: ')\n",
    "start = time.time()\n",
    "q_acc = evaluate(quantized_model, test_dl)\n",
    "end = time.time()\n",
    "q_time = end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmyC6Nze2jeJ"
   },
   "source": [
    "\n",
    "\n",
    "2. **During Layer Computation**:\n",
    "   ```\n",
    "   float32 input → temporary int8 → matrix multiply with int8 weights → float32 output\n",
    "   ```\n",
    "\n",
    "3. **Key Point**: We don't permanently quantize activations in dynamic quantization. The \"dynamic\" in dynamic quantization refers to:\n",
    "   - The temporary quantization of inputs during computation\n",
    "   - The scaling factors being calculated dynamically at runtime\n",
    "   - No permanent storage of quantized activations\n",
    "\n",
    "Dynamic quantization only permanently quantizes weights. The temporary input quantization is just an implementation detail to make matrix multiplication faster, and the outputs are immediately converted back to float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hKqpRLeyuN5h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weights: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0104, -0.0451, -0.0420,  ..., -0.0018, -0.0146,  0.0187],\n",
      "        [-0.0603,  0.0163,  0.0094,  ...,  0.0270, -0.0356,  0.0184],\n",
      "        [-0.0088,  0.0259,  0.0162,  ..., -0.0550,  0.0287,  0.0143],\n",
      "        ...,\n",
      "        [-0.0406, -0.0324,  0.0329,  ...,  0.0080, -0.0130, -0.0109],\n",
      "        [-0.0100, -0.0422,  0.0076,  ..., -0.0117, -0.0102,  0.0500],\n",
      "        [ 0.0027,  0.0210,  0.0457,  ..., -0.0049, -0.0600, -0.0109]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Dequantized weights: \n",
      "tensor([[ 0.0107, -0.0451, -0.0418,  ..., -0.0021, -0.0150,  0.0182],\n",
      "        [-0.0601,  0.0161,  0.0097,  ...,  0.0268, -0.0354,  0.0182],\n",
      "        [-0.0086,  0.0257,  0.0161,  ..., -0.0547,  0.0290,  0.0139],\n",
      "        ...,\n",
      "        [-0.0408, -0.0322,  0.0333,  ...,  0.0075, -0.0129, -0.0107],\n",
      "        [-0.0097, -0.0418,  0.0075,  ..., -0.0118, -0.0107,  0.0504],\n",
      "        [ 0.0032,  0.0215,  0.0461,  ..., -0.0054, -0.0601, -0.0107]])\n",
      "\n",
      "Prec   | Accuracy | Model Size | Time Taken\n",
      "FP32   | 0.4745   | 251.618    | 1.831720\n",
      "INT8   | 0.4753   | 76.834     | 2.670113\n"
     ]
    }
   ],
   "source": [
    "print('Original weights: ')\n",
    "print(model.fc1.weight)\n",
    "print('')\n",
    "print('Dequantized weights: ')\n",
    "print(torch.dequantize(quantized_model.fc1.weight()))\n",
    "print('')\n",
    "\n",
    "print(f\"{'Prec':<6} | {'Accuracy':<8} | {'Model Size':<10} | {'Time Taken'}\")\n",
    "print(f\"{'FP32':<6} | {o_acc:<8.4f} | {o_size:<10.3f} | {o_time:<.6f}\")\n",
    "print(f\"{'INT8':<6} | {q_acc:<8.4f} | {q_size:<10.3f} | {q_time:<.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMTDZyZHHOCPwfKaLNYsGWx",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
