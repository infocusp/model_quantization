{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGomPzAL4JEI"
   },
   "source": [
    "**Static Quantization**:\n",
    "   - Static quantization DOES quantize and store activations\n",
    "   - Uses fixed scaling factors determined during calibration\n",
    "   - Requires a separate calibration step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6td-nk6A3f30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonu/code/model_quantization/.venv/lib/python3.11/site-packages/fastprogress/fastprogress.py:107: UserWarning: Couldn't import ipywidgets properly, progress bar will use console behavior\n",
      "  warn(\"Couldn't import ipywidgets properly, progress bar will use console behavior\")\n"
     ]
    }
   ],
   "source": [
    "# importing the necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "\n",
    "_ = torch.manual_seed(0)\n",
    "\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    size = os.path.getsize(\"temp_delme.p\")/1e3\n",
    "    print('Size (KB):', size)\n",
    "    os.remove('temp_delme.p')\n",
    "    return size\n",
    "\n",
    "\n",
    "# Define the network:\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.reshape(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QNet, self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.reshape(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(model, train_dl, valid_dl, criterion, optimizer):\n",
    "    mb = master_bar(range(5))\n",
    "    for epoch in mb:\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        # Progress bar for training batches\n",
    "        pb = progress_bar(train_dl, parent=mb)\n",
    "\n",
    "        for inputs, labels in pb:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Compute training accuracy\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "            mb.child.comment = f\"Train Loss: {loss.item():.4f}\"\n",
    "\n",
    "        # Compute average train loss & accuracy\n",
    "        avg_train_loss = running_loss / len(train_dl)\n",
    "        train_accuracy = correct_train / total_train * 100\n",
    "\n",
    "        # Validation Phase (No Gradients)\n",
    "        val_loss = 0.0\n",
    "        correct_val, total_val = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Progress bar for validation\n",
    "            pb = progress_bar(valid_dl, parent=mb)\n",
    "\n",
    "            for inputs, labels in pb:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Compute validation accuracy\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                correct_val += (preds == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "                mb.child.comment = f\"Valid Loss: {loss.item():.4f}\"\n",
    "\n",
    "        # Compute average validation loss & accuracy\n",
    "        avg_val_loss = val_loss / len(valid_dl)\n",
    "        val_accuracy = correct_val / total_val * 100\n",
    "\n",
    "        # Write epoch summary\n",
    "        mb.write(f\"Epoch {epoch+1}: \"\n",
    "                 f\"Train Loss={avg_train_loss:.4f}, Train Acc={train_accuracy:.2f}% | \"\n",
    "                 f\"Val Loss={avg_val_loss: .4f}, Val Acc={val_accuracy: .2f}\")\n",
    "\n",
    "\n",
    "# evaluate\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"test acc\", correct / total)\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "def calibrate(model, dl):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, _) in enumerate(tqdm(dl)):\n",
    "            model(images)\n",
    "            if idx == 4:\n",
    "                break\n",
    "    return model\n",
    "\n",
    "\n",
    "def quantize_model(model, train_loader):\n",
    "    # Create quantization-ready model\n",
    "    qmodel = QNet().to('cpu')  # quantization needs to happen on CPU\n",
    "    qmodel.load_state_dict(model.state_dict())\n",
    "    qmodel.eval()\n",
    "\n",
    "    # Set qconfig for static quantization\n",
    "    qmodel.qconfig = torch.ao.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "    # Prepare model for quantization (adds observers)\n",
    "    qmodel = torch.ao.quantization.prepare(qmodel)\n",
    "\n",
    "    # Calibrate the model\n",
    "    calibrate(qmodel, train_loader)\n",
    "\n",
    "    # Convert to quantized model\n",
    "    qmodel = torch.ao.quantization.convert(qmodel)\n",
    "\n",
    "    return qmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-leIRPlf3pmu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ds length 40000\n",
      "test ds length 10000\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "tfms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# dataset and dataloader\n",
    "train_ds = torchvision.datasets.CIFAR10(\n",
    "    root='./data/cifar', train=True, transform=tfms, download=True)\n",
    "test_ds = torchvision.datasets.CIFAR10(\n",
    "    root='./data/cifar', train=False, transform=tfms, download=True)\n",
    "\n",
    "train_ds, valid_ds = random_split(train_ds, [40000, 10000])\n",
    "print(f\"train ds length {len(train_ds)}\")\n",
    "print(f\"test ds length {len(test_ds)}\")\n",
    "# train_ds = Subset(train_ds, range(100))\n",
    "# valid_ds = Subset(train_ds, range(100))\n",
    "# test_ds = Subset(train_ds, range(100))\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = torch.utils.data.DataLoader(\n",
    "    valid_ds, batch_size=batch_size, shuffle=False)\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MB3ZHwZP3rqa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# defining loss function and optimizer\n",
    "model = Net()\n",
    "model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# saving the model\n",
    "model_path = \"model.pkl\"\n",
    "if Path(model_path).exists():\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print('model loaded successfully')\n",
    "else:\n",
    "    train_model(model, train_dl, valid_dl, criterion, optimizer)\n",
    "    torch.save(model.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-AeAj9Y83t1N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before quantization\n",
      "Parameter containing:\n",
      "tensor([[ 0.0104, -0.0451, -0.0420,  ..., -0.0018, -0.0146,  0.0187],\n",
      "        [-0.0603,  0.0163,  0.0094,  ...,  0.0270, -0.0356,  0.0184],\n",
      "        [-0.0088,  0.0259,  0.0162,  ..., -0.0550,  0.0287,  0.0143],\n",
      "        ...,\n",
      "        [-0.0406, -0.0324,  0.0329,  ...,  0.0080, -0.0130, -0.0109],\n",
      "        [-0.0100, -0.0422,  0.0076,  ..., -0.0117, -0.0102,  0.0500],\n",
      "        [ 0.0027,  0.0210,  0.0457,  ..., -0.0049, -0.0600, -0.0109]],\n",
      "       requires_grad=True)\n",
      "torch.float32\n",
      "Size of the model before quantization\n",
      "Size (KB): 251.618\n",
      "Accuracy of the model before quantization: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 206.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc 0.4745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Weights before quantization')\n",
    "print(model.fc1.weight)\n",
    "print(model.fc1.weight.dtype)\n",
    "print('Size of the model before quantization')\n",
    "o_size = print_size_of_model(model)\n",
    "print('Accuracy of the model before quantization: ')\n",
    "tik = time.time()\n",
    "o_acc = evaluate(model, test_dl)\n",
    "tok = time.time()\n",
    "o_time = tok-tik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5ke5jcqT3wBk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonu/code/model_quantization/.venv/lib/python3.11/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying post training tynamic quantization on model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                                                       | 4/1250 [00:00<00:24, 51.65it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"applying post training tynamic quantization on model\")\n",
    "quantized_model = quantize_model(model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "s30ktm4Q3x5D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model summary\n",
      "QNet(\n",
      "  (quant): Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
      "  (conv1): QuantizedConv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.0658501610159874, zero_point=59)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): QuantizedConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), scale=0.14691703021526337, zero_point=56)\n",
      "  (fc1): QuantizedLinear(in_features=400, out_features=120, scale=0.15533238649368286, zero_point=68, qscheme=torch.per_channel_affine)\n",
      "  (fc2): QuantizedLinear(in_features=120, out_features=84, scale=0.08135645091533661, zero_point=43, qscheme=torch.per_channel_affine)\n",
      "  (fc3): QuantizedLinear(in_features=84, out_features=10, scale=0.09499918669462204, zero_point=64, qscheme=torch.per_channel_affine)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "Weights after quantization\n",
      "tensor([[  17,  -76,  -71,  ...,   -3,  -24,   31],\n",
      "        [ -79,   21,   12,  ...,   35,  -47,   24],\n",
      "        [ -16,   48,   30,  ..., -102,   53,   26],\n",
      "        ...,\n",
      "        [ -66,  -53,   54,  ...,   13,  -21,  -18],\n",
      "        [ -14,  -58,   10,  ...,  -16,  -14,   69],\n",
      "        [   4,   29,   63,  ...,   -7,  -83,  -15]], dtype=torch.int8)\n",
      "Size of the model after quantization\n",
      "Size (KB): 76.002\n",
      "Accuracy of the model after quantization: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:01<00:00, 171.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc 0.4726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"model summary\")\n",
    "print(quantized_model)\n",
    "print('Weights after quantization')\n",
    "print(torch.int_repr(quantized_model.fc1.weight()))\n",
    "print('Size of the model after quantization')\n",
    "q_size = print_size_of_model(quantized_model)\n",
    "print('Accuracy of the model after quantization: ')\n",
    "start = time.time()\n",
    "q_acc = evaluate(quantized_model, test_dl)\n",
    "end = time.time()\n",
    "q_time = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-P-EwcbU3mlA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weights: \n",
      "Parameter containing:\n",
      "tensor([[ 0.0104, -0.0451, -0.0420,  ..., -0.0018, -0.0146,  0.0187],\n",
      "        [-0.0603,  0.0163,  0.0094,  ...,  0.0270, -0.0356,  0.0184],\n",
      "        [-0.0088,  0.0259,  0.0162,  ..., -0.0550,  0.0287,  0.0143],\n",
      "        ...,\n",
      "        [-0.0406, -0.0324,  0.0329,  ...,  0.0080, -0.0130, -0.0109],\n",
      "        [-0.0100, -0.0422,  0.0076,  ..., -0.0117, -0.0102,  0.0500],\n",
      "        [ 0.0027,  0.0210,  0.0457,  ..., -0.0049, -0.0600, -0.0109]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Dequantized weights: \n",
      "tensor([[ 0.0101, -0.0453, -0.0423,  ..., -0.0018, -0.0143,  0.0185],\n",
      "        [-0.0601,  0.0160,  0.0091,  ...,  0.0266, -0.0358,  0.0183],\n",
      "        [-0.0087,  0.0260,  0.0162,  ..., -0.0552,  0.0287,  0.0141],\n",
      "        ...,\n",
      "        [-0.0406, -0.0326,  0.0332,  ...,  0.0080, -0.0129, -0.0111],\n",
      "        [-0.0101, -0.0420,  0.0072,  ..., -0.0116, -0.0101,  0.0499],\n",
      "        [ 0.0029,  0.0210,  0.0456,  ..., -0.0051, -0.0600, -0.0108]])\n",
      "\n",
      "Prec   | Accuracy | Model Size | Time Taken\n",
      "FP32   | 0.4745   | 251.618    | 1.524562\n",
      "INT8   | 0.4726   | 76.002     | 1.822876\n"
     ]
    }
   ],
   "source": [
    "print('Original weights: ')\n",
    "print(model.fc1.weight)\n",
    "print('')\n",
    "print('Dequantized weights: ')\n",
    "print(torch.dequantize(quantized_model.fc1.weight()))\n",
    "print('')\n",
    "\n",
    "print(f\"{'Prec':<6} | {'Accuracy':<8} | {'Model Size':<10} | {'Time Taken'}\")\n",
    "print(f\"{'FP32':<6} | {o_acc:<8.4f} | {o_size:<10.3f} | {o_time:<.6f}\")\n",
    "print(f\"{'INT8':<6} | {q_acc:<8.4f} | {q_size:<10.3f} | {q_time:<.6f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNZ1Ew/qu2V4xJUbMFvd4iR",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
